{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 외부 데이터 수집과 정제(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.search()함수를 사용하면 두 번째 매개변수의 문자열이 첫 번째 매개변수의 정규 표현식과 매칭되는지 확인 가능\n",
    "# 매칭되는 경우 Match 객체를 반환, 매칭되지 않는 경우 None을 반환\n",
    "re.search(r'a.*c', 'abc123DEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 예는 정규 표현식에 맞지 않으므로 None을 반환\n",
    "result = re.search(r'a.*D', 'abc123DEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 7), match='abc123D'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7\n",
      "abc123DEF\n"
     ]
    }
   ],
   "source": [
    "start, end = result.span()\n",
    "print(start, end)\n",
    "print(result.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 7), match='abc123D'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.IGNORECASE(또는 re.I)를 지정하면 대소문자를 무시\n",
    "re.search(r'a.*d', 'abc123DEF', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123DEFaddc\n"
     ]
    }
   ],
   "source": [
    "# Match 객체의 group() 메서드로 일치한 값을 추출\n",
    "# 매개변수에 0을 지정하면 매치된 모든 값을 반환\n",
    "m = re.search(r'a(.*)c', 'abc123DEFaddc')\n",
    "print(m.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bc123DEFadd'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 매개변수에 1 이상의 숫자를 지정하면 정규 표현식에서 0로 감싼 부분에 해당하는 값을 추출\n",
    "# 1이라면 1번째 그룹, 2라면 2번째 그룹 추출\n",
    "m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thi', 'is', 'pen']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.findall() 함수를 사용하면 정규 표현식에 맞는 모든 문자열을 리스트 타입으로 추출 가능\n",
    "# 다음 예에서는 2글자 이상의 단어를 모두 추출\n",
    "# \\w는 유니코드로 글자를 비교, 공백 문자는 \\s 등으로 추출할 수 있습니다.\n",
    "re.findall(r'\\w{2,3}', 'This is a pen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That is a pen'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.subO()함수를 사용하면 정규 표현식에 매칭되는 문자열 치환\n",
    "# 3번째 매개변수에 넣은 문자열에서 첫 번째 정규 표현식에 매칭되는 문자열을 2번째 매개변수 문자열로 치환\n",
    "re.sub(r'\\w{4}', 'That', 'This is a pen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(1, 4), match='abc'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = re.search(r'a.*c', ' abc123DEF')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match는 시작부터 일치하는지를 검사, search는 매칭되는 위치가 어디인지 탐색\n",
    "result = re.match(r'a.*c', 'abc123DEF')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 절에서 다운로드한 파일을 열고 html이라는 변수에 저장\n",
    "with open(r'C:\\Users\\user\\Desktop\\python workplace\\웹크롤링,스크래핑_실습데이터\\dp.html', encoding='utf-8') as f:\n",
    "    html = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.findall() 메서드를 통해 도서 하나에 해당하는 HTML을 추출\n",
    "for partial_html in re.findall(r'<td class=\"left\"><a.*?</td>', html, re.DOTALL):\n",
    "    # 도서의 URL을 추출\n",
    "    \n",
    "    # 그룹 0 은 매치된 전체문자\n",
    "    # () 로 지정한 그룹핑이 있다면 group(index) 로 찾을 수 있음\n",
    "    print(re.search(r'<a href=\"(.*?)\">', partial_html).group(0))\n",
    "    print(re.search(r'<a href=\"(.*?)\">', partial_html).group(1))\n",
    "    \n",
    "    url = re.search(r'<a href=\"(.*?)\">', partial_html).group(1) \n",
    "    url = 'http://www.hanbit.co.kr' + url\n",
    "    \n",
    "    # 태그를 제거해서 도서의 제목을 추출\n",
    "    # re.sub(pattern, new_text, text)\n",
    "    # text에서 pattern에 맞는 부분을 new_text로 대체\n",
    "    title = re.sub(r'<.*?>', '', partial_html)\n",
    "    title = unescape(title)\n",
    "    \n",
    "    print('url:', url)\n",
    "    print('title:', title)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElementTree 모듈을 로드\n",
    "from xml.etree import ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse() 함수로 파일을 읽고 ElementTree 객체를 생성\n",
    "tree = ElementTree.parse(r'C:\\Users\\user\\Desktop\\python workplace\\웹크롤링,스크래핑_실습데이터\\rss.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getroot() 메서드로 XML의 루트 element를 추출\n",
    "root = tree.getroot()\n",
    "root.findtext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "데이터프레임_리스트 = []\n",
    "for item in root.findall('channel/item/description/body/location/data'):\n",
    "    #find() 메서드로 elemnt 탐색, text 속성으로 값을 추출\n",
    "    tm_ef = item.find('tmEf').text\n",
    "    tmn = item.find('tmn').text\n",
    "    tmx = item.find('tmx').text\n",
    "    wf = item.find('wf').text\n",
    "    데이터프레임 = pd.DataFrame({\n",
    "        '일시':[tm_ef],\n",
    "        '최저기온':[tmn],\n",
    "        '최고기온':[tmx],\n",
    "        '날씨':[wf],\n",
    "    })\n",
    "    데이터프레임_리스트.append(데이터프레임)\n",
    "날씨정보 = pd.concat(데이터프레임_리스트)\n",
    "날씨정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "데이터프레임_리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file open, newline=''으로 개행문자 지정\n",
    "with open('top_cities.csv', 'w', newline='') as f:\n",
    "    # csv.writer는 파일 객체를 매개변수로 지정\n",
    "    writer = csv.writer(f)  \n",
    "    # 첫 번째 줄에는 헤더를 작성합니다.\n",
    "    writer.writerow(['rank', 'city', 'population'])  \n",
    "    # writerows()에 리스트를 전달하면 여러 개의 값을 출력\n",
    "    writer.writerows([\n",
    "        [1, '상하이', 24150000],\n",
    "        [2, '카라치', 23500000],\n",
    "        [3, '베이징', 21516000],\n",
    "        [4, '텐진', 14722100],\n",
    "        [5, '이스탄불', 14160467],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file open, newline=''으로 개행문자 지정\n",
    "with open('top_cities.csv', 'w', newline='',encoding='utf-8') as f:\n",
    "    # 첫 번째 매개변수에 파일 객체\n",
    "    # 두 번째 매개변수에 필드명 리스트를 지정\n",
    "    writer = csv.DictWriter(f, ['rank', 'city', 'population'])\n",
    "      # 첫 번째 줄에 헤더를 입력\n",
    "    writer.writeheader()\n",
    "      # writer.writerows()로 여러 개의 데이터를 딕셔너리 형태로 작성\n",
    "    writer.writerows([ \n",
    "          {'rank': 1, 'city': '상하이', 'population': 24150000},\n",
    "          {'rank': 2, 'city': '카라치', 'population': 23500000},\n",
    "          {'rank': 3, 'city': '베이징', 'population': 21516000},\n",
    "          {'rank': 4, 'city': '텐진', 'population': 14722110},\n",
    "          {'rank': 5, 'city': '이스탄불', 'population': 14160467},\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dic = chardet.detect(open('top_cities.csv', 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dic['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities =  [\n",
    "{'rank': 1, 'city': '상하이', 'population': 24150000},\n",
    "{'rank': 2, 'city': '카라치', 'population': 23500000},\n",
    "{'rank': 3, 'city': '베이징', 'population': 21516000},\n",
    "{'rank': 4, 'city': '텐진', 'population': 14722110},\n",
    "{'rank': 5, 'city': '이스탄불', 'population': 14160467},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_cities.json','w') as fw:\n",
    "    json.dump(cities,fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_cities.json','r') as fr:\n",
    "    json_file = json.load(fr)\n",
    "    print(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pandas.io import sql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = 'top_cities.db'\n",
    "TABLE_NAME = 'TOP_CITIES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_save(df, db_name, table_name):\n",
    "    with sqlite3.connect(db_name) as con:\n",
    "        try:\n",
    "            df.to_sql(name = table_name, con = con, index = False, if_exists='append') \n",
    "            #if_exists : {'fail', 'replace', 'append'} default : fail\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "        print(len(df), '건 저장완료..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_select(db_name, table_name):\n",
    "    with sqlite3.connect(db_name) as con: \n",
    "        try:\n",
    "            query = 'SELECT * FROM {}'.format(table_name)\n",
    "            df = pd.read_sql(query, con = con)\n",
    "        except Exception as e:\n",
    "            print(str(e)) \n",
    "        return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_delete(db_name, table_name):\n",
    "    with sqlite3.connect(db_name) as con: \n",
    "        try:\n",
    "            cur = con.cursor()\n",
    "            sql = 'DELETE FROM {}'.format(table_name)\n",
    "            cur.execute(sql)\n",
    "        except Exception as e:\n",
    "            print(str(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cites = pd.read_csv('top_cities.csv')\n",
    "db_save(top_cites, DB_NAME, TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_select(DB_NAME, TABLE_NAME)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "from urllib.request import urlopen\n",
    "from html import unescape\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(url):\n",
    "    \"\"\"\n",
    "    매개변수로 전달받을 url을 기반으로 웹 페이지를 추출\n",
    "    웹 페이지의 Content-Type 헤더를 통해 인코딩 형식 확인\n",
    "    반환값: str 자료형의 HTML\n",
    "    \"\"\"\n",
    "    f = urlopen(url)\n",
    "    # HTTP 헤더를 기반으로 인코딩 형식 추출\n",
    "    encoding = f.info().get_content_charset(failobj=\"utf-8\")\n",
    "    # 추출한 인코딩 형식을 기반으로 문자열 디코딩\n",
    "    html = f.read().decode(encoding)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(html):\n",
    "    \"\"\"\n",
    "    매개변수 html로 받은 HTML을 기반으로 정규 표현식을 사용해 도서 정보를 추출합니다.\n",
    "    반환값: 도서(dict) 리스트\n",
    "    \"\"\"\n",
    "    books = []\n",
    "    # re.findall()을 사용해 도서 하나에 해당하는 HTML을 추출\n",
    "    for partial_html in re.findall(r'<td class=\"left\"><a.*?</td>', html, re.DOTALL):\n",
    "        # 도서의 URL을 추출\n",
    "        url = re.search(r'<a href=\"(.*?)\">', partial_html).group(1)\n",
    "        url = 'http://www.hanbit.co.kr' + url\n",
    "        # 태그를 제거해서 도서의 제목 추출\n",
    "        title = re.sub(r'<.*?>', '', partial_html)\n",
    "        title = unescape(title)\n",
    "        books.append(pd.DataFrame({'url': [url], 'title': [title]}))\n",
    "\n",
    "    return pd.concat(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(db_path, books):\n",
    "    with sqlite3.connect(os.path.join('.', db_path)) as con: # sqlite DB 파일이 존재하지 않는 경우 파일생성\n",
    "        try:\n",
    "            books.to_sql(name = 'BOOKS_INFO', con = con, index = False, if_exists='append') \n",
    "            #if_exists : {'fail', 'replace', 'append'} default : fail\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    \n",
    "    query = 'SELECT * FROM BOOKS_INFO'\n",
    "    df = pd.read_sql(query, con = con)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = fetch('http://www.hanbit.co.kr/store/books/full_book_list.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>메타버스로 구현하는 나만의 세상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>IT CookBook, 생활 속 예제로 배우는 생생 데이터 분석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>IT CookBook, 데이터 과학을 위한 파이썬 프로그래밍(2판)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>리얼 오사카 [2023~2024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>IT CookBook, 처음 만나는 자동제어공학(2판)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "0  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "0  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "0  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "0  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "\n",
       "                                   title  \n",
       "0                      메타버스로 구현하는 나만의 세상  \n",
       "0    IT CookBook, 생활 속 예제로 배우는 생생 데이터 분석  \n",
       "0  IT CookBook, 데이터 과학을 위한 파이썬 프로그래밍(2판)  \n",
       "0                     리얼 오사카 [2023~2024]  \n",
       "0         IT CookBook, 처음 만나는 자동제어공학(2판)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = scrape(html)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>메타버스로 구현하는 나만의 세상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>IT CookBook, 생활 속 예제로 배우는 생생 데이터 분석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>IT CookBook, 데이터 과학을 위한 파이썬 프로그래밍(2판)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>리얼 오사카 [2023~2024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>IT CookBook, 처음 만나는 자동제어공학(2판)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "1  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "2  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "3  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "4  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "\n",
       "                                   title  \n",
       "0                      메타버스로 구현하는 나만의 세상  \n",
       "1    IT CookBook, 생활 속 예제로 배우는 생생 데이터 분석  \n",
       "2  IT CookBook, 데이터 과학을 위한 파이썬 프로그래밍(2판)  \n",
       "3                     리얼 오사카 [2023~2024]  \n",
       "4         IT CookBook, 처음 만나는 자동제어공학(2판)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop=True옵션을 주면 기존 인덱스를 버리고 재배열해준다.\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>메타버스로 구현하는 나만의 세상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>IT CookBook, 생활 속 예제로 배우는 생생 데이터 분석</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>IT CookBook, 데이터 과학을 위한 파이썬 프로그래밍(2판)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>리얼 오사카 [2023~2024]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.hanbit.co.kr/store/books/look.php?p...</td>\n",
       "      <td>IT CookBook, 처음 만나는 자동제어공학(2판)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "1  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "2  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "3  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "4  http://www.hanbit.co.kr/store/books/look.php?p...   \n",
       "\n",
       "                                   title  \n",
       "0                      메타버스로 구현하는 나만의 세상  \n",
       "1    IT CookBook, 생활 속 예제로 배우는 생생 데이터 분석  \n",
       "2  IT CookBook, 데이터 과학을 위한 파이썬 프로그래밍(2판)  \n",
       "3                     리얼 오사카 [2023~2024]  \n",
       "4         IT CookBook, 처음 만나는 자동제어공학(2판)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = save('books.db', df)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML 파일을 읽어 들이고, getroot() 메서드로 HtmlElement 객체 생성\n",
    "tree = lxml.html.parse(r'C:\\Users\\user\\Desktop\\python workplace\\웹크롤링,스크래핑_실습데이터\\dp.html')\n",
    "html = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cssselect() 메서드로 a 요소의 리스트를 추출 및 반복 수행\n",
    "for a in html.cssselect('a'):\n",
    "    # href 속성과 글자를 추출합니다.\n",
    "    print(a.get('href'), a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML 파일을 읽어 들이고 BeautifulSoup 객체를 생성\n",
    "with open(r'C:\\Users\\user\\Desktop\\python workplace\\웹크롤링,스크래핑_실습데이터\\full_book_list.html') as f:\n",
    "    soup = BeautifulSoup(f,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all() 메서드로 a 요소를 추출 및 반복 수행\n",
    "for a in soup.find_all('a'):\n",
    "    # href 속성과 글자를 추출합니다.\n",
    "    print(a.get('href'), a.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
